{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa9c6878-1246-4421-a178-3caa64ab0d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1547,  0.0897,  0.1649,  0.0013,  0.1421, -0.0092, -0.0526,  0.1932,\n",
       "          0.1911, -0.0037],\n",
       "        [ 0.0950,  0.0010,  0.2089,  0.0334, -0.0872,  0.0671, -0.1347,  0.0544,\n",
       "          0.0844,  0.1611]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "net = nn.Sequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\n",
    "X = torch.rand(2, 20)\n",
    "net(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03f4e278-4804-4fd2-96b2-6b89eb633827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0525, -0.0133,  0.0085, -0.1347,  0.0805,  0.2007,  0.0121,  0.1423,\n",
       "          0.0775,  0.0590],\n",
       "        [ 0.1742, -0.0619, -0.0534, -0.0850,  0.0560,  0.1060, -0.1070,  0.2264,\n",
       "          0.1109,  0.0877]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256) # Hidden layer(fully-connected)\n",
    "        self.out = nn.Linear(256, 10) # Output layer(fully-connected)\n",
    "    \n",
    "    # how to output based on the input\n",
    "    def forward(self, X):\n",
    "        return self.out(F.relu(self.hidden(X)))\n",
    "\n",
    "net = MLP() \n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95860813-695c-437b-aa7d-4bd36c9809de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0897,  0.2411, -0.3453, -0.0343, -0.2121, -0.1365, -0.1697,  0.0139,\n",
       "         -0.0314,  0.3589],\n",
       "        [-0.0339,  0.1304, -0.2281,  0.0861, -0.1791, -0.1028, -0.1966, -0.0430,\n",
       "         -0.0651,  0.1669]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how does Sequential works \n",
    "class mySequential(nn.Module): \n",
    "    def __init__(self, *args): \n",
    "        super().__init__() \n",
    "        for idx, module in enumerate(args): \n",
    "            # register the passed-in layer into submodule ordered dict of current model\n",
    "            self._modules[str(idx)] = module \n",
    "\n",
    "    def forward(self, X): \n",
    "        # ordered list ensure the traverse sequence follows the sequence which we add it\n",
    "        for block in self._modules.values(): \n",
    "            X = block(X) \n",
    "        return X\n",
    "\n",
    "# accept a 20-dim(size) vector and transform into a vector of size 256\n",
    "# ReLU turn all the negative numbers to 0 (given the ability to fit a non-linear graph)\n",
    "# accept a 256-dim features and map them down to 10\n",
    "net = mySequential(nn.Linear(20,256), nn.ReLU(), nn.Linear(256,10)) \n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf3be9dc-38f3-46e2-8b2d-ab69bceaeaf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1696, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A more flexible way to define a model\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F \n",
    "\n",
    "class FixedHiddenMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # random weight no need to calculate its grad\n",
    "        # define a 20*20 tensor with random weight （this W is fixed）\n",
    "        self.rand_weight = torch.rand((20, 20), requires_grad=False)\n",
    "        # define an input-layer, it will automatically define W & b, these param will keep optimized while training\n",
    "        self.linear = nn.Linear(20, 20)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.linear(X)\n",
    "        # defining a fully-connected layer(Linear layer) (Y = X·W + b)\n",
    "        X = F.relu(torch.mm(X, self.rand_weight) + 1)\n",
    "        # reuse the same linear layer\n",
    "        X = self.linear(X)\n",
    "\n",
    "        # Ensure L1(norm) is <= 1 (avoiding grad explosion)\n",
    "        while X.abs().sum() > 1:\n",
    "            X /= 2\n",
    "        return X.sum() \n",
    "\n",
    "net = FixedHiddenMLP()\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aab1eb6d-d02b-4308-a7f4-632ba0606e19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0851, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modular nesting\n",
    "class NestMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # (mini MLP)20-dim to 64-dim to 32-dim to 16-dim\n",
    "        self.net = nn.Sequential(nn.Linear(20, 64), nn.ReLU(), nn.Linear(64, 32), nn.ReLU())\n",
    "        self.linear = nn.Linear(32, 16) \n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.linear(self.net(X))\n",
    "\n",
    "# because the fixed W in FixedHiddenMLP is 20*20 , so before feeding the output to the last model\n",
    "# we need to transform to 20-dim\n",
    "chimera = nn.Sequential(NestMLP(), nn.Linear(16, 20), FixedHiddenMLP())\n",
    "chimera(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4699de3-7a26-4b33-b478-1fa19b0c21e5",
   "metadata": {},
   "source": [
    "# 2. Params management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3664787d-a90a-424c-8e98-ae853bbe9e26",
   "metadata": {},
   "source": [
    "#### A. access the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc5435f9-2e72-4934-8e11-5352032fa53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1894],\n",
      "        [-0.1894]], grad_fn=<AddmmBackward0>)\n",
      "OrderedDict([('weight', tensor([[ 0.3225, -0.1955,  0.2998, -0.1394,  0.0646, -0.1265,  0.0890,  0.1692]])), ('bias', tensor([-0.1894]))])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 1))\n",
    "X = torch.rand(size=(2, 4))\n",
    "print(net(X)) \n",
    "\n",
    "# Access the third layer (index 2) and print its parameters\n",
    "# .state_dict() tells the weight & bias of the current layer\n",
    "print(net[2].state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4147fb0-c44d-4380-8066-31f17ba74e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.parameter.Parameter'>\n",
      "\n",
      "\n",
      "Parameter containing:\n",
      "tensor([-0.1894], requires_grad=True)\n",
      "\n",
      "\n",
      "tensor([-0.1894])\n"
     ]
    }
   ],
   "source": [
    "# Now we know that the param is not just a tensor, \n",
    "# but an instance of the nn.Parameter class.print(type(net[2].bias))\n",
    "print(type(net[2].bias))\n",
    "print('\\n')\n",
    "\n",
    "print(net[2].bias) # this will tell us about the  and is grad included\n",
    "print('\\n')\n",
    "\n",
    "print(net[2].bias.data) # this will only tell us about the raw tensor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68990122-b4f7-44e7-b9b4-a0e0f92a28a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[2].weight.grad == None # chk if the grad of third layer's weight is empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb0b1259-f225-487b-9f34-d217e61a7c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('weight', torch.Size([8, 4])) ('bias', torch.Size([8]))\n",
      "('0.weight', torch.Size([8, 4])) ('0.bias', torch.Size([8])) ('2.weight', torch.Size([1, 8])) ('2.bias', torch.Size([1]))\n",
      "tensor([-0.1894])\n"
     ]
    }
   ],
   "source": [
    "# chk the weight and bias of the first linear layer\n",
    "print(*[(name, param.shape) for name, param in net[0].named_parameters()])\n",
    "\n",
    "# chk the weight & bias of each layer\n",
    "# net[0] hidden layer （4 inputs to 8 hidden units）\n",
    "# net[1] ReLU(activate function of hidden layer)\n",
    "# net[2] output layer\n",
    "print(*[(name, param.shape) for name, param in net.named_parameters()]) \n",
    "\n",
    "print(net.state_dict()['2.bias'].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d3695d57-6e07-4a9f-9d86-458680ce158b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0248],\n",
      "        [0.0248]], grad_fn=<AddmmBackward0>)\n",
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (block 0): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block 1): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block 2): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block 3): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (1): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def block1(): \n",
    "    # def a function: pick the input frm 4-dim to 8-dim to 4-dim \n",
    "    # 4 to 8: is like looking closer to pick the high-dim features to learn \n",
    "    # 8 to 4: is like concluding what the model will learn \n",
    "    # there're ReLU() at the end of these 2 layers to make sure it can handle complex curves \n",
    "    return nn.Sequential(nn.Linear(4,8), nn.ReLU(), nn.Linear(8,4), nn.ReLU())\n",
    "\n",
    "def block2(): \n",
    "    # now we start to define a model\n",
    "    # By splicing block1 4 times, we can get a model with 4*2 = 8 linear layers\n",
    "    net = nn.Sequential() \n",
    "    for i in range(4): \n",
    "        net.add_module(f'block {i}', block1()) \n",
    "    return net \n",
    "\n",
    "rgnet = nn.Sequential(block2(), nn.Linear(4,1)) \n",
    "print(rgnet(X)) \n",
    "print(rgnet) # to know what happen in each layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b07ece0c-eaa3-4201-8fb0-f9923af9748a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.4623,  0.3198, -0.1012,  0.2696, -0.2987,  0.3460, -0.2654, -0.4008])\n"
     ]
    }
   ],
   "source": [
    "# access the bias.data of first layer[0] of second sub0-block[1] of first big block[0], \n",
    "print(rgnet[0][1][0].bias.data) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29081913-cb61-4bfb-98ad-4593bc479659",
   "metadata": {},
   "source": [
    "#### B. Initialize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c51401e-ece7-48ac-8896-4cf81d410f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0113, -0.0150, -0.0047,  0.0043]) tensor(0.)\n",
      "tensor([1., 1., 1., 1.]) tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "def init_normal(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        # replace the value of the weight matrix to a random num that fits a normal distibution with mean of 0 and std deviation of 0.01\n",
    "        nn.init.normal_(m.weight, mean=0, std=0.01)\n",
    "        nn.init.zeros_(m.bias) \n",
    "net.apply(init_normal)\n",
    "print(net[0].weight.data[0], net[0].bias.data[0])\n",
    "\n",
    "\n",
    "def init_constant(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        nn.init.zeros_(m.bias)   \n",
    "net.apply(init_constant)\n",
    "print(net[0].weight.data[0], net[0].bias.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b9a61648-d4c3-4a7f-aad6-723948de1e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0768, -0.6218,  0.4811, -0.1065])\n",
      "tensor([[42., 42., 42., 42., 42., 42., 42., 42.]])\n",
      "Sequential(\n",
      "  (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=8, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Xavier initialize: Keep input, output, and gradient variances consistent across all layers.\n",
    "# A great method to prevent grad vanish or explode\n",
    "def init_xavier(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.xavier_uniform_(m.weight) \n",
    "        \n",
    "def init_42(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.constant_(m.weight, 42)\n",
    "\n",
    "net[0].apply(init_xavier)\n",
    "net[2].apply(init_42)\n",
    "print(net[0].weight.data[0])\n",
    "print(net[2].weight.data)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d33c8d7a-8e8d-468f-b540-a794b60fa67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init weight torch.Size([8, 4])\n",
      "Init weight torch.Size([1, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0000,  0.0000, -5.1336, -9.8545],\n",
       "        [-0.0000, -0.0000, -7.5281, -9.5152]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Customize initialization\n",
    "# [-10,10]: 10-(-10) = 20, in (-5,5): 5-(5) = 10, 10/20 = 1/2 \n",
    "# [5,10]: 10-5 = 5, 5/20 = 1/4 \n",
    "def my_init(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        print(\"Init\", *[(name, param.shape) for name, param in m.named_parameters()][0])\n",
    "        \n",
    "        # uniform_: pick a random num locally frm [-10,10]\n",
    "        nn.init.uniform_(m.weight,-10, 10)\n",
    "        m.weight.data *= m.weight.data.abs() >= 5 # abs <= 5, *0; else *1\n",
    "\n",
    "net.apply(my_init)\n",
    "net[0].weight[:2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "451cb107-2ce3-4e67-adb6-08d9f8dab4e6",
   "metadata": {},
   "source": [
    "$$\n",
    "w \\sim \\begin{cases} \n",
    "U(5, 10) & \\text{可能性 } \\frac{1}{4} \\\\ \n",
    "0 & \\text{可能性 } \\frac{1}{2} \\\\ \n",
    "U(-10, -5) & \\text{可能性 } \\frac{1}{4} \n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fbe04e4e-77bc-4f78-a352-8a5e7aa9c334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([42.,  6., 27., 29.])\n",
      "tensor([[ 4.2000e+01,  6.0000e+00,  2.7000e+01,  2.9000e+01],\n",
      "        [ 6.0000e+00,  6.0000e+00, -1.5281e+00, -3.5152e+00],\n",
      "        [ 1.3968e-02,  1.1984e+01,  1.4727e+01, -2.1026e+00],\n",
      "        [ 1.5819e+01,  6.0000e+00,  6.0000e+00,  6.0000e+00],\n",
      "        [ 6.0000e+00,  6.0000e+00,  6.0000e+00,  6.0000e+00],\n",
      "        [ 6.0000e+00,  1.4117e+01, -1.0386e+00,  6.0000e+00],\n",
      "        [ 1.4862e+01,  6.0000e+00, -3.3229e+00, -3.0641e+00],\n",
      "        [ 6.0000e+00,  6.0000e+00, -6.1504e-01,  1.4682e+01]])\n"
     ]
    }
   ],
   "source": [
    "# direct initialization\n",
    "net[0].weight.data[:] += 1\n",
    "net[0].weight.data[0, 0] = 42\n",
    "net[0].weight.data[0, 2] = 27\n",
    "\n",
    "print(net[0].weight.data[0]) \n",
    "print(net[0].weight.data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "27f3a38d-612b-4ce8-a530-4a3590462cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True, True, True, True, True, True, True])\n",
      "tensor(0.2366)\n",
      "tensor([True, True, True, True, True, True, True, True])\n",
      "tensor(100.)\n"
     ]
    }
   ],
   "source": [
    "# share a layer\n",
    "shared_layer = nn.Linear(8,8) \n",
    "net = nn.Sequential(nn.Linear(4,8), nn.ReLU(), \n",
    "                    shared_layer, nn.ReLU(),\n",
    "                    shared_layer, nn.ReLU(), \n",
    "                    nn.Linear(8,1)) \n",
    "\n",
    "# now we've define net[2] and net[5] as the same layer(shared_layer)\n",
    "net(X) \n",
    "print(net[2].weight.data[0] == net[4].weight.data[0]) \n",
    "print(net[2].weight.data[0,0] )\n",
    "\n",
    "net[2].weight.data[0,0] = 100 \n",
    "print(net[2].weight.data[0] == net[4].weight.data[0])\n",
    "print(net[2].weight.data[0,0] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb0d9f6-fc93-4809-a95a-7f164c64824b",
   "metadata": {},
   "source": [
    "# 3. Custom layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "37b3f5cc-d7d3-4417-962f-fff49d2c6b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2., -1.,  0.,  1.,  2.])\n",
      "tensor(-5.5879e-09, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn \n",
    "\n",
    "# define a layer without any params\n",
    "class CenteredLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        \n",
    "    def forward(self, X):\n",
    "        return X - X.mean() \n",
    "\n",
    "layer = CenteredLayer()\n",
    "print(layer(torch.FloatTensor([1, 2, 3, 4, 5]))) \n",
    "\n",
    "net = nn.Sequential(nn.Linear(8, 128), CenteredLayer()) \n",
    "Y = net(torch.rand(4, 8))\n",
    "print(Y.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "21f193af-7f31-4c0e-bd1f-0c874ac50a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.9110, -1.1737,  0.8375],\n",
      "        [-1.1390, -1.3665,  2.9099],\n",
      "        [-0.4137, -0.2264,  0.4246],\n",
      "        [-0.1646,  0.0253, -1.3546],\n",
      "        [ 0.9051,  0.4764,  0.9985]], requires_grad=True)\n",
      "tensor([[0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.9762]])\n",
      "tensor([[12.5350],\n",
      "        [12.7621]])\n"
     ]
    }
   ],
   "source": [
    "class MyLinear(nn.Module):\n",
    "    def __init__(self, in_units, units):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(in_units, units))\n",
    "        self.bias = nn.Parameter(torch.randn(units,)) # (units, ) this tuple only has one element\n",
    "    def forward(self, X):\n",
    "        linear = torch.matmul(X, self.weight.data) + self.bias.data\n",
    "        return F.relu(linear) \n",
    "\n",
    "linear = MyLinear(5, 3)\n",
    "print(linear.weight)\n",
    "print(linear(torch.rand(2, 5)))\n",
    "\n",
    "net = nn.Sequential(MyLinear(64, 8), MyLinear(8, 1))\n",
    "print(net(torch.rand(2, 64)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e1f1b1-b0e9-4cef-a13c-31b4c219d9ab",
   "metadata": {},
   "source": [
    "# 4. Read & write file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a87d9d86-5c27-4fc1-b531-69f2d2e96cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_34828\\3155839136.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  x2 = torch.load('x-file') # load file\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "x = torch.arange(4)\n",
    "torch.save(x, 'x-file') \n",
    "x2 = torch.load('x-file') # load file\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "46a558d0-5efa-4b00-ae8f-1c8ea394281c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_34828\\2061157211.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  x2, y2 = torch.load('x-files')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3]), tensor([0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can also save a tensor list to the Memory \n",
    "y = torch.zeros(4)\n",
    "torch.save([x, y],'x-files')\n",
    "x2, y2 = torch.load('x-files')\n",
    "(x2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e0954abb-b6d7-4a6d-bb78-4419981f1c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_34828\\1011335214.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  mydict2 = torch.load('mydict')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'x': tensor([0, 1, 2, 3]), 'y': tensor([0., 0., 0., 0.])}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can also define a dict and display it as a more readable format\n",
    "mydict = {'x': x, 'y': y}\n",
    "torch.save(mydict, 'mydict')\n",
    "mydict2 = torch.load('mydict')\n",
    "mydict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "398fe4e3-2db7-431a-827d-b8f2570a799e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_34828\\1031783973.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  clone.load_state_dict(torch.load('mlp.params'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (hidden): Linear(in_features=20, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)\n",
    "        self.output = nn.Linear(256, 10)\n",
    "    def forward(self, x):\n",
    "        return self.output(F.relu(self.hidden(x)))\n",
    "net = MLP()\n",
    "X = torch.randn(size=(2, 20))\n",
    "Y = net(X) \n",
    "\n",
    "# save all the params of model\n",
    "torch.save(net.state_dict(), 'mlp.params') \n",
    "clone = MLP() # Attention: the param is randomly initialize so it's different with the one we've saved\n",
    "clone.load_state_dict(torch.load('mlp.params'))\n",
    "clone.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
